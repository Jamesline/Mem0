openai_api_key: '<your_openai_api_key>'
inference_server_url: 'http://<your_hf_textgen_inference_server_address>:<server_port_number>/'
tokenizer_model: '<hf_profile/hf_model>'